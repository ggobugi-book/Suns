{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from konlpy.tag import Kkma\n",
    "from konlpy.utils import pprint\n",
    "from konlpy.tag import Twitter\n",
    "from konlpy.tag import Komoran\n",
    "from gensim.models import word2vec\n",
    "import matplotlib.pyplot as plt\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('./test.txt','r',encoding='utf-8')\n",
    "lines = file.read()\n",
    "\n",
    "sentences = re.split('(?<=[2-9]\\n)|(?<=[0-9][0-9]\\n)|(?<=[0-9][0-9][0-9]\\n)', lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent=[]\n",
    "for stuff in sentences:\n",
    "        sent.append(stuff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = word2vec.LineSentence(result)\n",
    "model = word2vec.Word2Vec(data,\n",
    "        size=200,window=10,hs=1,min_count=2,sg=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "for line in sent:\n",
    "    r = []\n",
    "    words = twitter.pos(line,norm=True)\n",
    "    for word in words:\n",
    "        if word[1] not in [\"Punctuation\",\"Eomi\",\"Josa\"]:\n",
    "            r.append(word[0])\n",
    "            result.append(\" \".join(r).strip())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save(\"toji.model\")\n",
    "\n",
    "# model = word2vec.Word2Vec.load('toji.model')\n",
    "# things = model.most_similar(positive[\"집\"])\n",
    "\n",
    "print(list(model.wv.vocab.keys()))\n",
    "# print(things) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# stop_words=stop_words.split(' ')\n",
    "\n",
    "# result = []\n",
    "# for w in noun_adj_list:\n",
    "#     word_tokens = word_tokenize(w)\n",
    "#     if word_tokens not in stop_words:\n",
    "#         result.append(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = word2vec.Word2Vec(data, size=200,window=10,hs=1,min_count=2,sg=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# window크기 5, 최소 출현수 2, skip-gram, 10000번 학습\n",
    "model = Word2Vec(noun_adj_list,window = 5,min_count=2,sg=1,iter=10000)\n",
    "\n",
    "print(list(model.wv.vocab.keys()))\n",
    "print(\"vocab length : %d\"%len(model.wv.vocab))\n",
    "\n",
    "print(model.wv.most_similar(\"범\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
